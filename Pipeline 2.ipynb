{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline 2 description\n",
    "# Fit a beta distribution to all the tissue columns w/o the nan values in the training set.\n",
    "# Use the beta distributions conditioned on the location to fill the NaN values.\n",
    "# Once you have finished filling in the NaNs, your training set will be complete\n",
    "# To fill in the values in the test set, take the test vector's values, locations and find the\n",
    "# top x distributions that the vector is most likely to come from.\n",
    "# Use these top x as the training set for a regressor that will be used to predict the missing values in the training\n",
    "# set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load imports\n",
    "import math\n",
    "import numpy as np \n",
    "from IPython.display import Image  \n",
    "import pandas\n",
    "import os\n",
    "from scipy.stats import beta\n",
    "# Enter your directory here\n",
    "os.chdir('/Users/abkhanna/Documents/workspace/Princeton/cos424/a2/methylation_imputation-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_bed = pandas.read_csv('data/intersected_final_chr1_cutoff_20_train.bed', sep='\\t', header=None)\n",
    "sample_p_bed = pandas.read_csv('data/intersected_final_chr1_cutoff_20_sample_partial.bed', sep='\\t', header=None)\n",
    "sample_f_bed = pandas.read_csv('data/intersected_final_chr1_cutoff_20_sample_full.bed', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the distributions\n",
    "# first trial with just a single tissue\n",
    "tissue_sample = train_bed[4]\n",
    "tissue_sample_list = tissue_sample\n",
    "# remove NaNs\n",
    "tissue_sample_no_nans = [x for x in tissue_sample_list if ~np.isnan(x)]\n",
    "a, b, loc, scale = beta.fit(tissue_sample_no_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the beta for the test vector\n",
    "# use the beta to generate the values for the missing values.\n",
    "beta_gen = np.random.beta\n",
    "tissue_sample_nan_rep = [x if ~np.isnan(x) else beta_gen(a, b) for x in tissue_sample_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now time to do it with the entire set!\n",
    "def fill_col(col):\n",
    "    col_sample_list = col\n",
    "    col_sample_no_nans = [x for x in col_sample_list if ~np.isnan(x)]\n",
    "    a, b, loc, scale = beta.fit(col_sample_no_nans)\n",
    "    beta_gen = np.random.beta\n",
    "    col_sample_nan_rep = [x if ~np.isnan(x) else beta_gen(a, b) for x in col_sample_list]\n",
    "    return col_sample_nan_rep\n",
    "\n",
    "table1 = train_bed[list(range(4,37))]\n",
    "table2 = []\n",
    "for i in range(4, 37):\n",
    "    table2.append(fill_col(table1[i]))\n",
    "\n",
    "table2 = pandas.DataFrame(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Now create a list of (a,b) pairs so you can figure out which distribution is the most likely \n",
    "# for your similarity metric\n",
    "# table2 has all the NaN values filled in in the training set.\n",
    "ab_tuples = []\n",
    "def get_ab(col):\n",
    "    a, b, loc, scale = beta.fit(col)\n",
    "    return a,b\n",
    "\n",
    "for i in range(4,37):\n",
    "    ab_tuples.append(get_ab(table2[i]))\n",
    "\n",
    "print len(ab_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-13659490456237456.0, 19), (-468922803856.88477, 28), (-247037332581.60791, 26), (-12298065041.707794, 31), (-10978471043.584106, 20), (-8051881059.2469997, 32), (-32805912.004562154, 7), (-4406257.3454944938, 27), (-317697.32312980184, 21), (-95469.340965576077, 18), (-49589.869748645382, 13), (-14437.079474929746, 16), (-7156.5482661051547, 0), (-6441.9824834351766, 22), (-4167.9483290805319, 23), (-4035.3804815743883, 25), (-2193.2234922808666, 17), (-1536.2867341735198, 24), (-92.968290898778704, 29), (384.45164212161984, 9), (618.98387205880874, 2), (1220.3286454002207, 4), (1383.3589021019866, 30), (1604.5434066759576, 1), (1741.0272154780146, 3), (1763.2054999725726, 6), (1826.2384759577812, 11), (1914.6054993076173, 15), (2054.0610890510643, 10), (2267.9794906005231, 8), (2397.0167268304494, 5), (2420.2267945418512, 14), (2432.5848001531817, 12)]\n"
     ]
    }
   ],
   "source": [
    "# once we have the list of ab tuples, we can use them to calculate the probability\n",
    "# that the test vector came from any one of these distributions\n",
    "test_vector_nans = sample_p_bed[4] # 4th column has the data, others are informatory\n",
    "test_vector_no_nans = [x for x in test_vector_nans if ~np.isnan(x)]\n",
    "similarity_scores = []\n",
    "i = 0\n",
    "for a, b in ab_tuples:\n",
    "    running_product = 0\n",
    "    for meth in test_vector_no_nans:\n",
    "        assert (0 < meth < 1)\n",
    "        probability = beta.logpdf(meth, a, b)\n",
    "        running_product = running_product + probability\n",
    "    similarity_scores.append((running_product, i))\n",
    "    i = i + 1\n",
    "\n",
    "# sort the scores by the first tuple value\n",
    "sorted_similarity = sorted(similarity_scores, key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take the top x number of these vectors, and use their values to create a regression.\n",
    "top_x = 3\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
