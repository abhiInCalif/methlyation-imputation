{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline 2 description\n",
    "# Fit a beta distribution to all the tissue columns w/o the nan values in the training set.\n",
    "# Use the beta distributions conditioned on the location to fill the NaN values.\n",
    "# Once you have finished filling in the NaNs, your training set will be complete\n",
    "# To fill in the values in the test set, take the test vector's values, locations and find the\n",
    "# top x distributions that the vector is most likely to come from.\n",
    "# Use these top x as the training set for a regressor that will be used to predict the missing values in the training\n",
    "# set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load imports\n",
    "import math\n",
    "import numpy as np \n",
    "from IPython.display import Image  \n",
    "import pandas\n",
    "import os\n",
    "from scipy.stats import beta\n",
    "# Enter your directory here\n",
    "os.chdir('/Users/abkhanna/Documents/workspace/Princeton/cos424/a2/methylation_imputation-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_bed = pandas.read_csv('data/intersected_final_chr1_cutoff_20_train.bed', sep='\\t', header=None)\n",
    "sample_p_bed = pandas.read_csv('data/intersected_final_chr1_cutoff_20_sample_partial.bed', sep='\\t', header=None)\n",
    "sample_f_bed = pandas.read_csv('data/intersected_final_chr1_cutoff_20_sample_full.bed', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the distributions\n",
    "# first trial with just a single tissue\n",
    "tissue_sample = train_bed[4]\n",
    "tissue_sample_list = tissue_sample\n",
    "# remove NaNs\n",
    "tissue_sample_no_nans = [x for x in tissue_sample_list if ~np.isnan(x)]\n",
    "a, b, loc, scale = beta.fit(tissue_sample_no_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the beta for the test vector\n",
    "# use the beta to generate the values for the missing values.\n",
    "beta_gen = np.random.beta\n",
    "tissue_sample_nan_rep = [x if ~np.isnan(x) else beta_gen(a, b) for x in tissue_sample_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abkhanna/Documents/workspace/Princeton/cos424/a2/lib/python2.7/site-packages/scipy/optimize/minpack.py:161: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# now time to do it with the entire set!\n",
    "def fill_col(col):\n",
    "    col_sample_list = col\n",
    "    col_sample_no_nans = [x for x in col_sample_list if ~np.isnan(x)]\n",
    "    a, b, loc, scale = beta.fit(col_sample_no_nans)\n",
    "    beta_gen = np.random.beta\n",
    "    col_sample_nan_rep = [x if ~np.isnan(x) else beta_gen(a, b) for x in col_sample_list]\n",
    "    return col_sample_nan_rep\n",
    "\n",
    "table1 = train_bed[list(range(4,37))]\n",
    "table2 = []\n",
    "for i in range(4, 37):\n",
    "    table2.append(fill_col(table1[i]))\n",
    "table2 = pandas.DataFrame(table2).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.437500\n",
       "1         0.660377\n",
       "2         0.852459\n",
       "3         0.974683\n",
       "4         0.906250\n",
       "5         0.777778\n",
       "6         0.750000\n",
       "7         0.521739\n",
       "8         0.875000\n",
       "9         0.820513\n",
       "10        0.544304\n",
       "11        0.833333\n",
       "12        0.863158\n",
       "13        0.822222\n",
       "14        0.529412\n",
       "15        0.835165\n",
       "16        0.613636\n",
       "17        0.892857\n",
       "18        0.860759\n",
       "19        0.404255\n",
       "20        0.750000\n",
       "21        0.592593\n",
       "22        0.358974\n",
       "23        0.239130\n",
       "24        0.122449\n",
       "25        0.393443\n",
       "26        0.316667\n",
       "27        0.796610\n",
       "28        0.652174\n",
       "29        0.437500\n",
       "            ...   \n",
       "379521    0.768293\n",
       "379522    0.848837\n",
       "379523    0.772727\n",
       "379524    0.812500\n",
       "379525    0.585106\n",
       "379526    0.830000\n",
       "379527    0.676768\n",
       "379528    0.647059\n",
       "379529    0.747368\n",
       "379530    0.890244\n",
       "379531    0.564103\n",
       "379532    0.851351\n",
       "379533    0.698413\n",
       "379534    0.846154\n",
       "379535    0.621212\n",
       "379536    0.804878\n",
       "379537    0.703704\n",
       "379538    0.703704\n",
       "379539    0.896104\n",
       "379540    0.847458\n",
       "379541    0.904762\n",
       "379542    0.619718\n",
       "379543    0.651685\n",
       "379544    0.838710\n",
       "379545    0.945652\n",
       "379546    0.898734\n",
       "379547    0.972973\n",
       "379548    0.815789\n",
       "379549    0.676923\n",
       "379550    0.843750\n",
       "Name: 32, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# Now create a list of (a,b) pairs so you can figure out which distribution is the most likely \n",
    "# for your similarity metric\n",
    "# table2 has all the NaN values filled in in the training set.\n",
    "ab_tuples = []\n",
    "def get_ab(col):\n",
    "    a, b, loc, scale = beta.fit(col)\n",
    "    return a,b\n",
    "\n",
    "for i in range(0,32):\n",
    "    ab_tuples.append(get_ab(table2[i]))\n",
    "\n",
    "print len(ab_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# once we have the list of ab tuples, we can use them to calculate the probability\n",
    "# that the test vector came from any one of these distributions\n",
    "test_vector_nans = sample_p_bed[4] # 4th column has the data, others are informatory\n",
    "test_vector_no_nans = [x for x in test_vector_nans if ~np.isnan(x)]\n",
    "similarity_scores = []\n",
    "i = 0\n",
    "for a, b in ab_tuples:\n",
    "    running_product = 0\n",
    "    for meth in test_vector_no_nans:\n",
    "        assert (0 < meth < 1)\n",
    "        probability = beta.logpdf(meth, a, b)\n",
    "        running_product = running_product + probability\n",
    "    similarity_scores.append((running_product, i))\n",
    "    i = i + 1\n",
    "\n",
    "# sort the scores by the first tuple value\n",
    "sorted_similarity = sorted(similarity_scores, key=lambda tup: tup[0])\n",
    "print len(sorted_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Len: 379551\n",
      "xs len: 379551\n",
      "Y len: 379551\n",
      "X shape: (379551, 1)\n",
      "Y shape: (379551,)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# take the top x number of these vectors, and use their values to create a regression.\n",
    "top_x = 3\n",
    "\n",
    "y1 = table2[sorted_similarity[-1][1]].as_matrix().tolist()\n",
    "# y2 = table2[sorted_similarity[-2][1]].as_matrix().tolist()\n",
    "# y3 = table2[sorted_similarity[-3][1]].as_matrix().tolist()\n",
    "# print len(y1)\n",
    "# print len(y2)\n",
    "# print len(y3)\n",
    "xs = train_bed[1].as_matrix().tolist()\n",
    "X = xs # + xs + xs\n",
    "print \"X Len: {0}\".format(len(X))\n",
    "print \"xs len: {0}\".format(len(xs))\n",
    "Y = y1 # + y2 + y3\n",
    "print \"Y len: {0}\".format(len(Y))\n",
    "X = np.array(X).reshape(-1,1)\n",
    "print \"X shape: {0}\".format(X.shape)\n",
    "Y = np.array(Y)\n",
    "print \"Y shape: {0}\".format(Y.shape)\n",
    "print \"Done!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the window_size\n",
    "window_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the elements of X and Y into chunks of 5,000 to prevent fitting time complexity issues\n",
    "# len of x = len of y\n",
    "X_partials_array = []\n",
    "Y_partials_array = []\n",
    "for i in range(0,len(X), window_size):\n",
    "    X_partials_array.append(X[i:i+window_size])\n",
    "    Y_partials_array.append(Y[i:i+window_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://datascience.stackexchange.com/questions/989/\n",
    "# ... svm-using-scikit-learn-runs-endlessly-and-never-completes-execution\n",
    "# suggests subsampling the data set rather than using the entirety of it.\n",
    "from sklearn.svm import SVR\n",
    "svrs = [] # array of svr kernels split across every 5000 rows\n",
    "for i in range(0, len(X_partials_array)):\n",
    "    svr_rbf = SVR(kernel='poly', C=1e3, gamma=0.01, cache_size=7000)\n",
    "    svr_rbf.fit(X_partials_array[i], Y_partials_array[i])\n",
    "    svrs.append(svr_rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from these svrs, predict the missing values in the test vector!\n",
    "test_tissue = sample_p_bed[4]\n",
    "nan_vector = sample_p_bed[5]\n",
    "test_loc_vector = sample_p_bed[1]\n",
    "filled_test_tissue = []\n",
    "predict_count = 0\n",
    "orc = 0\n",
    "\n",
    "def predict(i):\n",
    "    svr_bucket = int(i / window_size) # window_size is defined a few cells above\n",
    "    svr_regressor = svrs[svr_bucket]\n",
    "    y_predict = svr_regressor.predict(test_loc_vector[i])\n",
    "#     over_range_count = 0\n",
    "    if y_predict > 1:\n",
    "#         over_range_count = over_range_count + 1\n",
    "        return [0.45], 1\n",
    "    if y_predict < -1:\n",
    "        return [0.45], 1\n",
    "    return y_predict, over_range_count\n",
    "\n",
    "for i in range(len(nan_vector)):\n",
    "    if nan_vector[i] == 0 or np.isnan(test_tissue[i]):\n",
    "        # fill it in!!!\n",
    "        predict_count = predict_count + 1\n",
    "        y_predict, n_orc = predict(i)\n",
    "        orc = orc + n_orc\n",
    "#         assert 0 < y_predict[0] < 1\n",
    "        filled_test_tissue.append(y_predict[0])\n",
    "    elif nan_vector[i] == 1:\n",
    "        # value is valid! just use it\n",
    "        y_actual = test_tissue[i]\n",
    "        assert 0 < y_actual < 1\n",
    "        filled_test_tissue.append(y_actual)\n",
    "    else:\n",
    "        raise ValueError('Invalid state in nan_vector')\n",
    "\n",
    "print \"Filled_test_tissue: {0}\".format(len(filled_test_tissue))\n",
    "print \"Test Tissue: {0}\".format(len(test_tissue))\n",
    "print \"Predict Count: {0}\".format(predict_count)\n",
    "print \"Over range Count: {0}\".format(orc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_f_bed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e548e9089823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfull_values_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_f_bed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfull_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfull_values_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_test_tissue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_values_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfilled_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilled_test_tissue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_test_tissue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_values_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_f_bed' is not defined"
     ]
    }
   ],
   "source": [
    "# now we need to do the comparisons to check how well our imputation worked!\n",
    "# to test / grade our efforts, we will use r^2 correlation between this vector + the actual \"ground truth\" vector\n",
    "# We will also use RMSE value, and a graph of the residuals to understand where the error is most concentrated.\n",
    "# Due to a lack of time, we will not be able to iterate on this design; however, hopefully this will at the very\n",
    "# least provide good insight into how we could progress further if we wanted to.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "full_values_vector = sample_f_bed[4]\n",
    "full_values = [full_values_vector[x] for x in range(len(filled_test_tissue)) if ~np.isnan(full_values_vector[x])]\n",
    "filled_test = [filled_test_tissue[x] for x in range(len(filled_test_tissue)) if ~np.isnan(full_values_vector[x])]\n",
    "diff_test = [filled_test[x] - full_values[x] for x in range(len(filled_test))]\n",
    "print len(full_values)\n",
    "print len(filled_test)\n",
    "print(np.corrcoef(filled_test, full_values))\n",
    "print(rmse(np.array(filled_test), np.array(full_values)))\n",
    "plt.figure(1)\n",
    "plt.scatter(np.array(full_values), np.array(filled_test))\n",
    "plt.figure(2)\n",
    "plt.scatter([i for i in range(len(filled_test))], diff_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "-1.79642610239",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6be63b9ae9c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilled_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     print x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: -1.79642610239"
     ]
    }
   ],
   "source": [
    "for x in filled_test:\n",
    "#     print x\n",
    "    assert -1 <= x <= 1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
